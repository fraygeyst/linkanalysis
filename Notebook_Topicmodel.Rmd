---
title: "R Notebook"
output: html_notebook

---


```{r setup, include=TRUE, echo=TRUE, warning=FALSE, message=FALSE}
knitr::opts_chunk$set(echo=TRUE, warning=FALSE)
library(knitr)
library(stm)
library(quanteda)
library(RSQLite)
library(ggplot2)
library(wordcloud)
library(visNetwork)

```



```{r db, warning=FALSE, message=FALSE}
con <- RSQLite::dbConnect(RSQLite::SQLite(), "dbjoinedData.db")
data <- RSQLite::dbGetQuery(con, "SELECT tweet_text FROM joinedData LIMIT 100000")
processed <- textProcessor(data$tweet_text, language = "de", customstopwords = c("mal", "w채re", "h채tte", "denen", "rund", "eben", "vielleicht", "jemand", "gar", "beim", "daraus", "daran", "schon", "statt", "daher", "daf체r", "darin", "darum", "dass", "dar체ber", "davon"))
out <- prepDocuments(processed$documents, processed$vocab, processed$meta, lower.thresh = 5)
```


Estimate topic models for different K


```{r}
model1 <- stm(documents = out$documents, vocab = out$vocab, K = 10, max.em.its = 20, data = out$meta, init.type = "Spectral")
```

```{r}
model2 <- stm(documents = out$documents, vocab = out$vocab, K = 20, max.em.its = 20, data = out$meta, init.type = "Spectral")
```

```{r}
model3 <- stm(documents = out$documents, vocab = out$vocab, K = 30, max.em.its = 20, data = out$meta, init.type = "Spectral")
```

```{r}
model4 <- stm(documents = out$documents, vocab = out$vocab, K = 40, max.em.its = 20, data = out$meta, init.type = "Spectral")
```

```{r}
model5 <- stm(documents = out$documents, vocab = out$vocab, K = 50, max.em.its = 20, data = out$meta, init.type = "Spectral")
```

```{r}
model6 <- stm(documents = out$documents, vocab = out$vocab, K = 60, max.em.its = 20, data = out$meta, init.type = "Spectral")
```

```{r}
model7 <- stm(documents = out$documents, vocab = out$vocab, K = 70, max.em.its = 20, data = out$meta, init.type = "Spectral")
```

```{r}
model8 <- stm(documents = out$documents, vocab = out$vocab, K = 80, max.em.its = 20, data = out$meta, init.type = "Spectral")
```

```{r}
model9 <- stm(documents = out$documents, vocab = out$vocab, K = 90, max.em.its = 20, data = out$meta, init.type = "Spectral")
```

```{r}
model10 <- stm(documents = out$documents, vocab = out$vocab, K = 100, max.em.its = 20, data = out$meta, init.type = "Spectral")
```

### Evaluate model performance


Create vector with semCoh and exclu for all models

```{r}
semCoh <- semanticCoherence(model = model1, documents = out$documents)
semCoh <- c(semCoh, semanticCoherence(model = model2, documents = out$documents))
semCoh <- c(semCoh, semanticCoherence(model = model3, documents = out$documents))
semCoh <- c(semCoh, semanticCoherence(model = model4, documents = out$documents))
semCoh <- c(semCoh, semanticCoherence(model = model5, documents = out$documents))
semCoh <- c(semCoh, semanticCoherence(model = model6, documents = out$documents))
semCoh <- c(semCoh, semanticCoherence(model = model7, documents = out$documents))
semCoh <- c(semCoh, semanticCoherence(model = model8, documents = out$documents))
semCoh <- c(semCoh, semanticCoherence(model = model9, documents = out$documents))
semCoh <- c(semCoh, semanticCoherence(model = model10, documents = out$documents))

exclu <- exclusivity(model = model1)
exclu <- c(exclu, exclusivity(model = model2))
exclu <- c(exclu, exclusivity(model = model3))
exclu <- c(exclu, exclusivity(model = model4))
exclu <- c(exclu, exclusivity(model = model5))
exclu <- c(exclu, exclusivity(model = model6))
exclu <- c(exclu, exclusivity(model = model7))
exclu <- c(exclu, exclusivity(model = model8))
exclu <- c(exclu, exclusivity(model = model9))
exclu <- c(exclu, exclusivity(model = model10))
```



Calculate semantic coherence and exclusivity for all models


```{r}

semCoh_model1 <- semanticCoherence(model = model1, documents = out$documents)
semCoh_model2 <- semanticCoherence(model = model2, documents = out$documents)
semCoh_model3 <- semanticCoherence(model = model3, documents = out$documents)
semCoh_model4 <- semanticCoherence(model = model4, documents = out$documents)
semCoh_model5 <- semanticCoherence(model = model5, documents = out$documents)
semCoh_model6 <- semanticCoherence(model = model6, documents = out$documents)
semCoh_model7 <- semanticCoherence(model = model7, documents = out$documents)
semCoh_model8 <- semanticCoherence(model = model8, documents = out$documents)
semCoh_model9 <- semanticCoherence(model = model9, documents = out$documents)
semCoh_model10 <- semanticCoherence(model = model10, documents = out$documents)

exclu_model1 <- exclusivity(model = model1)
exclu_model2 <- exclusivity(model = model2)
exclu_model3 <- exclusivity(model = model3)
exclu_model4 <- exclusivity(model = model4)
exclu_model5 <- exclusivity(model = model5)
exclu_model6 <- exclusivity(model = model6)
exclu_model7 <- exclusivity(model = model7)
exclu_model8 <- exclusivity(model = model8)
exclu_model9 <- exclusivity(model = model9)
exclu_model10 <- exclusivity(model = model10)

```



Generate dataframe


```{r}

color <- c()
for (i in 1:11) {
  if (i == 11) {
    next
  }
  for (j in (1:(10*i))) {
    color = c(color, paste("t",i,sep=""))
  }
}
dataf <- data.frame(semCoh, exclu, color)

```



Plot semantic coherence and exclusivity in scatterplot



```{r}
ggplot(dataf, aes(x=semCoh, y=exclu, color=color ))+
  geom_point(size = 1, alpha = 0.7) +
  labs(x = "Semantic coherence",
       y = "Exclusivity")
```




Create data frame with mean semantic coherence and mean exclusivity by number of topics

```{r}

df <- data.frame(topics=c(10,20,30,40,50,60,70,80,90,100), semCoh=c(mean(semCoh_model1), mean(semCoh_model2), mean(semCoh_model3), mean(semCoh_model4), mean(semCoh_model5), mean(semCoh_model6), mean(semCoh_model7), mean(semCoh_model8), mean(semCoh_model9), mean(semCoh_model10)))
df2 <- data.frame(topics=c(10,20,30,40,50,60,70,80,90,100), exclu=c(mean(exclu_model1), mean(exclu_model2), mean(exclu_model3), mean(exclu_model4), mean(exclu_model5), mean(exclu_model6), mean(exclu_model7), mean(exclu_model8), mean(exclu_model9), mean(exclu_model10)))

```



# plot semantic coherence in line chart

```{r}

ggplot(data=df, aes(x=topics, y=semCoh, group=1)) +
  geom_line()+
  geom_point()+
  labs(x = "Number of topics",
       y = "Semantic Coherence")+
  scale_x_continuous(n.breaks = 10)+
  theme_bw()+
  theme(
    plot.background = element_blank(),
    #panel.grid.major = element_blank(),
    panel.grid.minor = element_blank(),
    panel.border = element_blank(),
    axis.line = element_line(color = 'black'),
    text = element_text(size=14),
    axis.title.x = element_text(margin = margin(t = 20, r = 0, b = 0, l = 0), size=13),
    axis.title.y = element_text(margin = margin(t = 0, r = 20, b = 0, l = 0), size=13)
    )

```


Plot exclusivity in line chart

```{r}

ggplot(data=df2, aes(x=topics, y=exclu, group=1)) +
  geom_line()+
  geom_point()+
  labs(x = "Number of topics",
       y = "Exclusivity")+
  scale_x_continuous(n.breaks = 10)+
  theme_bw()+
  theme(
    plot.background = element_blank(),
    #panel.grid.major = element_blank(),
    panel.grid.minor = element_blank(),
    panel.border = element_blank(),
    axis.line = element_line(color = 'black'),
    text = element_text(size=14),
    axis.title.x = element_text(margin = margin(t = 20, r = 0, b = 0, l = 0), size=13),
    axis.title.y = element_text(margin = margin(t = 0, r = 20, b = 0, l = 0), size=13)
  )
  

```



Visualize topic proportions


```{r}

plot.STM(model8, type ="summary", text.cex = 0.3)

```


``` {r}
plot(model8, type = "label", topics = c(9, 32, 31), main = "Themenbegriffe")

```


Display word cloud for topics' keywords

```{r}

cloud(model8, topic=9, max.words = 100)
cloud(model8, topic=32, max.words = 100)

```



```{r}
plot.STM(model8, type="perspectives", topics = c(61,17))
```




Linkanalyse

10.000 Daten

``` {r}

nodes <- jsonlite::fromJSON("https://raw.githubusercontent.com/fraygeyst/linkanalysis/main/Datenaufbereitung%2010.000/visNodes10.000.json")

edges <- jsonlite::fromJSON("https://raw.githubusercontent.com/fraygeyst/linkanalysis/main/Datenaufbereitung%2010.000/visEdges10.000.json")


visNetwork(nodes, edges, height = "1000px", width = "100%") %>%
  visOptions(selectedBy = "group", 
             highlightNearest = TRUE, 
             nodesIdSelection = TRUE) %>%
  visPhysics(stabilization = FALSE) 


```


100.000 Daten

``` {r}

nodes <- jsonlite::fromJSON("https://raw.githubusercontent.com/fraygeyst/linkanalysis/main/Datenaufbereitung%20100.000/visNodes100.000.json")

edges <- jsonlite::fromJSON("https://raw.githubusercontent.com/fraygeyst/linkanalysis/main/Datenaufbereitung%20100.000/visEdges100.000.json")


visNetwork(nodes, edges, height = "1000px", width = "100%") %>%
  visOptions(selectedBy = "group", 
             highlightNearest = TRUE, 
             nodesIdSelection = TRUE) %>%
  visPhysics(stabilization = FALSE)


```

``` {r}

nodes <- jsonlite::fromJSON("https://raw.githubusercontent.com/fraygeyst/linkanalysis/main/Datenaufbereitung%20100.000/Model7/visNodes100.000Model7.json")

edges <- jsonlite::fromJSON("https://raw.githubusercontent.com/fraygeyst/linkanalysis/main/Datenaufbereitung%20100.000//Model7/visEdges100.000Model7.json")


visNetwork(nodes, edges, height = "1000px", width = "100%") %>%
  visOptions(selectedBy = "group", 
             highlightNearest = TRUE, 
             nodesIdSelection = TRUE) %>%
  visPhysics(stabilization = FALSE)


```

Print topic keywords

```{r}

labels <-labelTopics(model8, n = 5)
for (i in 1:length(labels$prob[,1])) {
  cat(paste("Topic",i,"\n"))
  for (j in 1:length(labels$prob[1,])) {
    cat(paste(labels$prob[i,j],"\n"), sep =" ")
  }
  cat("\n")
}

```




